sims <- replicate(N, {
# H0: mu = 0
x <- rnorm(100, mean = 0)            # Genera muestras de H0 (H0 es correcta)
test <- t.test(x, mu = 0)$p.value    # Testea H0
# Añade condición de éxito para calcular la probabilidad de
# "Rechazar H_0 a pesar de ser correcta"
})
print(paste("alpha =", alpha, "| p(incorrectly reject H0) = ", mean(sims)))
# Añade condición de éxito para calcular la probabilidad de
# "Rechazar H_0 a pesar de ser correcta"
test < alpha
sims <- replicate(N, {
# H0: mu = 0
x <- rnorm(100, mean = 0)            # Genera muestras de H0 (H0 es correcta)
test <- t.test(x, mu = 0)$p.value    # Testea H0
# Añade condición de éxito para calcular la probabilidad de
# "Rechazar H_0 a pesar de ser correcta"
test < alpha
})
print(paste("alpha =", alpha, "| p(incorrectly reject H0) = ", mean(sims)))
N <- 5000
alpha <- 0.05
sims <- replicate(N, {
# H0: mu = 0
x <- rnorm(100, mean = 0)            # Genera muestras de H0 (H0 es correcta)
test <- t.test(x, mu = 0)$p.value    # Testea H0
# Añade condición de éxito para calcular la probabilidad de
# "Rechazar H_0 a pesar de ser correcta"
test < alpha
})
print(paste("alpha =", alpha, "| p(incorrectly reject H0) = ", mean(sims)))
alpha <- 0.01
sims <- replicate(N, {
# H0: mu = 0
x <- rnorm(100, mean = 0)            # Genera muestras de H0 (H0 es correcta)
test <- t.test(x, mu = 0)$p.value    # Testea H0
# Añade condición de éxito para calcular la probabilidad de
# "Rechazar H_0 a pesar de ser correcta"
test < alpha
})
print(paste("alpha =", alpha, "| p(incorrectly reject H0) = ", mean(sims)))
# (X - mu) / (sd / sqrt(n)) ~ T_(n - 1)
t.test(homeo_weight_loss$weight_loss_Kg)
# (X - mu) / (sd / sqrt(n)) ~ T_(n - 1)
t.test(homeo_weight_loss$weight_loss_Kg, mu = 2, alternative = "greater")
# (X - mu) / (sd / sqrt(n)) ~ T_(n - 1)
t.test(homeo_weight_loss$weight_loss_Kg, mu = 2, alternative = "less")
# (X - mu) / (sd / sqrt(n)) ~ T_(n - 1)
t.test(homeo_weight_loss$weight_loss_Kg, mu = 2, alternative = "two.sided")
# (X - mu) / (sd / sqrt(n)) ~ T_(n - 1)
t.test(homeo_weight_loss$weight_loss_Kg, mu = 2, alternative = "less")
# (X - mu) / (sd / sqrt(n)) ~ T_(n - 1)
my_test = t.test(homeo_weight_loss$weight_loss_Kg, mu = 2, alternative = "less")
# siempre se pone de la alternativa, como dice el parametro
2 * my_test$p.value
# siempre se pone de la alternativa, como dice el parametro
my_test$p.value
pt(t_contraste, 49)
library("tidyverse")
library(readr)
pharma_weight_loss <- read_csv("data_2/pharma_weight_loss.csv")
View(pharma_weight_loss)
# 2.-
my_test = t.test(pharma_weight_loss$weight_loss_Kg, mu = 0, alternative = "greater")
my_test$p.value
# 2.-
# ASUNCIONES:
#  - M.A.S/POB. INF. --> el nº de muestras es muy pequeña con la poblacion total
#  - NORMALIDAD -->
bins = nclass.FD(pharma_weight_loss$weight_loss_Kg)
ggplot(pharma_weight_loss, aes(x = weight_loss_Kg)) + geom_histogram(bins = bins)
ggplot(pharma_weight_loss, aes(x = weight_loss_Kg)) + geom_histogram()
# Ha > 0;
my_test = t.test(pharma_weight_loss$weight_loss_Kg, mu = 0, alternative = "greater")
my_test
# para calcular la relevancia del resultado:
mean(pharma_weight_loss$weight_loss_Kg)
# para calcular la relevancia del resultado:
mean(pharma_weight_loss$weight_loss_Kg) / nrow(pharma_weight_loss)
# para calcular la relevancia del resultado:
mean(pharma_weight_loss$weight_loss_Kg) / sd(pharma_weight_loss$weight_loss_Kg)
library("effectsize")
effectsize(pharma_weight_loss)
effectsize(pharma_weight_loss$weight_loss_Kg)
effectsize(my_test)
cohens_d = mean(pharma_weight_loss$weight_loss_Kg) / sd(pharma_weight_loss$weight_loss_Kg)
?effectsize()
my_test
source("C:/Users/machi/Downloads/CEU/segundo año/primer semestre/estadistica/REPASO FINAL/T4_inter_conf_e_hipotesis/iq_español.R", echo=TRUE)
# 2.- buscar estadistic de contraste
X = mean(iq_spanish$iq)
X
bins = nclass.FD(iq_spanish$iq)
ggplot(iq_spanish, aes(x = iq)) + geom_histogram(bins = bins)
min(iq_spanish$iq)
nrow(iq_spanish)
?dchisq
# 3.- calcular el p_valor
S = var(iq_spanish$iq)
S
# 3.- calcular el p_valor
# S ^ 2 = var(iq_spanish$iq)  # --> 388.6902
((29) * 388.6902) / 15 ^ 2
t.test(iq_spanish$iq, X)
?t.test
t.test(iq_spanish$iq)
# p_valor = P(X ^ 2_(29) > 50.09785) = 1 - P(X ^ 2_(29) <= 50.09785) =
# = 1 - pchisq(50.09785, 29)
t.test(iq_spanish$iq)
# p_valor = P(X ^ 2_(29) > 50.09785) = 1 - P(X ^ 2_(29) <= 50.09785) =
# = 1 - pchisq(50.09785, 29)
1 - pchisq(50.09785, 29)
# p_valor = P(X ^ 2_(29) > 50.09785) = 2 * (1 - P(X ^ 2_(29) <= 50.09785)) =
# = 2 * (1 - pchisq(50.09785, 29))
2 * (1 - pchisq(50.09785, 29))  # --> 0.008814888
# p_valor = P(X ^ 2_(29) > 50.09785) = 2 * (1 - P(X ^ 2_(29) <= 50.09785)) =
# = 2 * (1 - pchisq(50.09785, 29))
p_valor = 2 * (1 - pchisq(50.09785, 29))  # --> 0.01762978
# p_valor = P(X ^ 2_(29) > 50.09785) = 2 * (1 - P(X ^ 2_(29) <= 50.09785)) =
# = 2 * (1 - pchisq(50.09785, 29))
p_valor = 2 * (1 - pchisq(50.1, 29))  # --> 0.01762978
p_valor
power_var_test <- function(n, H0_sigma2 = 15 ^ 2, true_sigma2 = 388.6902,
significance = 0.05, N = 5000) {
sims <- replicate(N, {
data <- rnorm(n, sd = sqrt(true_sigma2)) # datos donde la Ha es cierta
var_stat <- (n - 1) * var(data) / 15 ^ 2
p_value <-  2 * (1 - pchisq(var_stat, df = n - 1))
p_value < significance
})
}
sims
sum(sims) / N
mean(sims)
power_var_test(10)
power_var_test <- function(n, H0_sigma2 = 15 ^ 2, true_sigma2 = 388.6902,
significance = 0.05, N = 5000) {
sims <- replicate(N, {
data <- rnorm(n, sd = sqrt(true_sigma2)) # datos donde la Ha es cierta
var_stat <- (n - 1) * var(data) / 15 ^ 2
p_value <-  2 * (1 - pchisq(var_stat, df = n - 1))
p_value < significance  # TRUE si rechazo la H0 (acepto la Ha)
})
}
power_var_test(10)
power_var_test <- function(n, H0_sigma2 = 15 ^ 2, true_sigma2 = 388.6902,
significance = 0.05, N = 5000) {
sims <- replicate(N, {
data <- rnorm(n, sd = sqrt(true_sigma2)) # datos donde la Ha es cierta
var_stat <- (n - 1) * var(data) / 15 ^ 2
p_value <-  2 * (1 - pchisq(var_stat, df = n - 1))
p_value < significance  # TRUE si rechazo la H0 (acepto la Ha)
})
mean(sims)# --> 0.0074 --> P(acepatr HA | Ha es cierta (sigma ^ 2 = 388.6902))
}
power_var_test(10)
power_var_test(10) > 0.9
power_var_test(1:100) > 0.9
power_var_test(seq(10, 80, by = 10)) > 0.9
ns = seq(10, 80, by = 10)
power_var_test = Vectorize(power_var_test)
ns = seq(10, 80, by = 10)
power_var_test(ns) > 0.9
source("C:/Users/machi/Downloads/CEU/segundo año/primer semestre/estadistica/REPASO FINAL/T4_inter_conf_e_hipotesis/iq_español.R", echo=TRUE)
plot(ns, power_values)
power_values = power_var_test(ns) > 0.9
plot(ns, power_values)
power_var_test = Vectorize(power_var_test)
ns = seq(10, 80, by = 10)
power_values = power_var_test(ns)
plot(ns, power_values)
plot(ns, power_values, type = "o")
abline(h = 0.9, col = 2, lty = 2)
?power.t.test
power.t.test(
delta = 0.5, # medio kg de incremento
sd = 4.1, # en el enunciado
sig.level = 0.01, # enunciado
power = 0.9, # enunciado
type = "one.sample",
alternative = "one.sided"  # Ha: mu > 63.5kg
)
source("~/.active-rstudio-document", echo=TRUE)
library("tidyverse")
bins = nclass.FD(howell1$height)
ggplot(howell1, aes(x = height), col = male) + geom_histogram(bins = bins)
library("effectsize")
ggplot(howell1, aes(x = height)) + geom_histogram(bins = bins)
howell1$age > 18
howell1[age > 18]
howell1[howell1$age > 18]
View(howell1)
howell1[howell1$age >= 18, ]
bins = nclass.FD(howell1$height)
howell_adultos = howell1[howell_adultos$age >= 18, ]
howell_adultos = howell1[howell1$age >= 18, ]
ggplot(howell_adultos, aes(x = height)) + geom_histogram(bins = bins)
bins = nclass.FD(howell_adultos$height)
ggplot(howell_adultos, aes(x = height)) + geom_histogram(bins = bins)
ggplot(howell_adultos, aes(x = height, col = male)) + geom_histogram(bins = bins)
# los datos categoricos deben codificarse como factores
howell_adultos$male = as.factor(howell_adultos$male)
bins = nclass.FD(howell_adultos$height)
ggplot(howell_adultos, aes(x = height, col = male)) + geom_histogram(bins = bins)
ggplot(howell_adultos, aes(x = height, col = male)) + geom_density()
# Ha: mu_men != mu_women  --> mu_men - mu_women != 0
t.test(men, women, alternative = "two.sided", mu = 0, paired = TRUE)
# Ha: mu_men != mu_women  --> mu_men - mu_women != 0
men = howell_adultos[howell_adultos$male == 1, ]
women = howell_adultos[howell_adultos$male == 0, ]
t.test(men, women, alternative = "two.sided", mu = 0, paired = TRUE)
t.test(men, women, alternative = "two.sided", mu = 0)
t.test(men$height, women$height, alternative = "two.sided", mu = 0)
t_test = t.test(men$height, women$height, alternative = "two.sided", mu = 0)
# tamaño del efecto:
effectsize(t_test)
t.test(howell_adultos$height)
t.test(men$height, women$height, alternative = "two.sided", mu = 0,var.equal = TRUE)
t_test2 = t.test(men$height, women$height, alternative = "two.sided", mu = 0,var.equal = TRUE)
effectsize(t_test2)
library("tidyverse")
library("effectsize")
library(readr)
gbef_long <- read_table("data_3/gbef_long.csv")
View(gbef_long)
colnames(gbef_long) = c("ID", "class", "gbef")
gbe
View(gbef_long)
gbef_Post = gbef_long[gbef_long$class == "Postop", ]
gbef_Pre = gbef_long[gbef_long$class == "Preop", ]
gbef_Pre
gbef_Post
View(c(gbef_Post, gbef_Pre))
View(c(gbef_Post)
View(gbef_Post)
source("C:/Users/machi/Downloads/CEU/segundo año/primer semestre/estadistica/REPASO FINAL/T4_inter_conf_e_hipotesis/tamaño_gbef.R", echo=TRUE)
ggplot(gbef_long, aes(x = gbef, col = class)) + geom_density()
gbef_Pre = gbef_long[gbef_long$class == "\"Preop\"", ]
gbef_Post = gbef_long[gbef_long$class == "\"Postop\"", ]
gbef_Pre
gbef_Post
diferencia_pre_post = gbef_Post$gbef - gbef_Pre$gbef
diferencia_pre_post
hist(diferencia_pre_post)
ggplot(diferencia_pre_post, aes = gbef) + geom_histogram()
ggplot(diferencia_pre_post, aes(gbef)) + geom_histogram()
ggplot(diferencia_pre_post) + geom_histogram()
# 3.- aplico t.test
# Ha: mu_post > mu_pre  --> mu_post - mu_pre > 0 --> mu_diferencias > 0
t.test(diferencia_pre_post)
?t.test
# 3.- aplico t.test
# Ha: mu_post > mu_pre  --> mu_post - mu_pre > 0 --> mu_diferencias > 0
t.test(diferencia_pre_post, alternative = "greater")
# 3.- aplico t.test
# Ha: mu_post > mu_pre  --> mu_post - mu_pre > 0 --> mu_diferencias > 0
t.test(diferencia_pre_post, alternative = "greater", paired = TRUE)
# 3.- aplico t.test
# Ha: mu_post > mu_pre  --> mu_post - mu_pre > 0 --> mu_diferencias > 0
t.test(diferencia_pre_post, alternative = "greater")
# otra manera (con 2 poblaciones):
t.test(gbef_Post$gbef, gbef_Pre$gbef, alternative = "greater", paired = TRUE)
# otra manera (con 2 poblaciones):
my_t = t.test(gbef_Post$gbef, gbef_Pre$gbef, alternative = "greater", paired = TRUE)
effectsize(my_t)
# otra manera (con 2 poblaciones):
my_t = t.test(
gbef_Post$gbef, gbef_Pre$gbef,
alternative = "greater",
paired = TRUE,
conf.level = 0.99
)
my_t
effectsize(my_t)
# 3.- aplico t.test
# Ha: mu_post > mu_pre  --> mu_post - mu_pre > 0 --> mu_diferencias > 0
t.test(diferencia_pre_post, alternative = "greater")
# otra manera (con 2 poblaciones):
my_t = t.test(
gbef_Post$gbef, gbef_Pre$gbef,
alternative = "greater",
paired = TRUE
)
effectsize(my_t)
# otra manera (con 2 poblaciones):
my_t = t.test(
gbef_Post$gbef, gbef_Pre$gbef,
alternative = "greater",
paired = TRUE,
conf.level = 0.99
)
effectsize(my_t)
power.t.test(
delta = 18.075,
sd = sd(diferencia_pre_post),
sig.level = 0.01,
power = 0.9,
type = "one.sample",
alternative = "one.sided"
)
?power
# argumentos principales: datos de A, B
# 3.1.- vamoas a generar datoscuya media y varianza cuadren con los datos del
# enunciado.
# reto: generar 16 muestras normales de media 3 y varianza 24
rnorm(16)
rnorm(16, mean = 3, sd = sqrt(24))
sim = rnorm(16, mean = 3, sd = sqrt(24))
var(sim)
# var(sim)
# estandarizar simulaciones: restar la media a las varaibles
sim - mean(sim)
# var(sim)
# estandarizar simulaciones: restar la media a las varaibles
sim - mean(sim) / sd
sd
# var(sim)
# estandarizar simulaciones: restar la media a las varaibles
sim_z - mean(sim) / sqrt(24)
# var(sim)
# estandarizar simulaciones: restar la media a las varaibles
sim_z = sim - mean(sim) / sqrt(24)
sim_z
mean(sim_z)
# var(sim)
# estandarizar simulaciones: restar la media a las varaibles
sim_z = (sim - mean(sim)) / sqrt(24)
mean(sim_z)
sd(sim_z)
sim = rnorm(16, mean = 3, sd = sqrt(24))
# var(sim)
# estandarizar simulaciones: restar la media a las varaibles
sim_z = (sim - mean(sim)) / sqrt(24)
mean(sim_z)
sd(sim_z)
# var(sim)
# estandarizar simulaciones: restar la media a las varaibles
sim_z = (sim - mean(sim)) / sd(sim)
mean(sim_z)  # mas menos 0
sd(sim_z)  # mas menos 1
sim = rnorm(16, mean = 3, sd = sqrt(24))
# var(sim)
# estandarizar simulaciones: restar la media a las varaibles
sim_z = (sim - mean(sim)) / sd(sim)
mean(sim_z)  # mas menos 0
sd(sim_z)
mean(sim_z + 3)  # mas menos 0
sd(sim_z * 24)  # --> 1
sd(sim_z * sqrt(24))  # --> 24 --> sqrt(24) * sd(sim_z)
var(sim_z * sqrt(24))  # --> 4.898979 --> sqrt(24) * sd(sim_z)
sim_majas = sd(sim_z * 24)
sim_majas = sim_z * sqrt(24) + 3
# comprobacion:
mean(sim_majas)
var(sim_majas)
# H0:
# Ha: var(A) > 2 * var(B) --> var(A) / var(B) > 2
var.test(sim_A, sim_B, ratio = 2, alternative = "greater")
source("C:/Users/machi/Downloads/CEU/segundo año/primer semestre/estadistica/REPASO FINAL/T4_inter_conf_e_hipotesis/var_test.R", echo=TRUE)
# H0:
# Ha: var(A) > 2 * var(B) --> var(A) / var(B) > 2
var.test(sim_A, sim_B, ratio = 2, alternative = "greater")
library("tidyverse")
library("effectsize")
library(readr)
spain_league <- read_csv("data_4/spain_league.csv")
View(spain_league)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
rowSums(spain_league$hgoal)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
rowSums(spain_league$hgoal, )
?rowSums
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
colSums(spain_league$hgoal)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
colSums(spain_league$hgoal, dims = 1)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
colSums(spain_league)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
colSums(spain_league$hgoal)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
colSums(spain_league$hgoal, spain_league$vgoal))
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
colSums(spain_league$hgoal, spain_league$vgoal)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
colSums(spain_league[spain_league$hgoal, ])
pv
probs_xy
source("C:/Users/machi/Downloads/CEU/segundo año/primer semestre/estadistica/REPASO FINAL/T3_Variables_Aleatorias/cruces_igual_negras.R", echo=TRUE)
probs_xy
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
sum(spain_league$hgoal)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
sum(spain_league$hgoal) + sum(spain_league$Date)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
sum(spain_league$hgoal) + sum(spain_league$vgoal)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
sum(spain_league$hgoal) + sum(spain_league$vgoal) / nrow(spain_league)
nrow(spain_league)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
(sum(spain_league$hgoal) + sum(spain_league$vgoal)) / nrow(spain_league)
# sum(Xi) ~ N(n * lambda, n * lambda)
# sum(Xi) / n ~ N(lambda, lambda / n)
mu = (sum(spain_league$hgoal) + sum(spain_league$vgoal)) / nrow(spain_league)
lambda = mu
?qnorm
sd(mu)
sd((sum(spain_league$hgoal) + sum(spain_league$vgoal)) / nrow(spain_league))
sd(spain_league$hgoal)
sd((sum(spain_league$hgoal) + sum(spain_league$vgoal)))
spain_league$hgoal + spain_league$vgoal
sd(spain_league$hgoal + spain_league$vgoal)
# 3.- regla del 67-95-99:
# P(a < X < b) = 0.98
# Z = X - lambda / sqrt(lambda / n) --> tipificar la normal
# P(a < Z < b)
qnorm(0.01)
qnorm(0.99)
# 3.- regla del 67-95-99:
# P(a < X < b) = 0.98
# Z = X - lambda / sqrt(lambda / n) --> tipificar la normal
# P(a < Z < b)
a = qnorm(0.01) # --> -2.326348
b = qnorm(0.99) # --> 2.326348
X = mean(spain_league$hgoal + spain_league$vgoal)
X
n = nrow(spain_league)
n
X = mean(spain_league$hgoal + spain_league$vgoal)  # --> 2.840657
n = nrow(spain_league)  # --> 26195
X - 2.33 * sqrt(X / n)
X + 2.33 * sqrt(X / n)
spain_2021 = spain_league[spain_league$Season == 2021, ]
X = mean(spain_2021$hgoal + spain_2021$vgoal)  # --> 2.840657
n = nrow(spain_league)  # --> 26195
X
n
n = nrow(spain_2021)  # --> 26195
n
X - 2.33 * sqrt(X / n)
X + 2.33 * sqrt(X / n)
mean(spain_2021$hgoal)
X = mean(spain_2021$hgoal)  # --> 1.421053
X - 2.33 * sqrt(X / n)
X + 2.33 * sqrt(X / n)
lambda_est = mean(spain_2021$hgoal)  # --> 1.421053
z = c(a, b)
lambda_est + z * sqrt(lambda_est / n)
?dpois
source("~/.active-rstudio-document", echo=TRUE)
?prop.test
prop.test(4, 80, 0.5)
prop.test(4, 80, 0.5, alternative = "less")
source("~/.active-rstudio-document", echo=TRUE)
ab_nueva = ab_testing[ab_testing$page_design == "old", ]
ab_nueva = ab_testing[ab_testing$page_design == "new", ]
ab_vieja = ab_testing[ab_testing$page_design == "old", ]
ab_nueva
ab_vieja
X_nueva = mean(ab_nueva)
X_vieja = mean(ab_vieja)
X_nueva = mean(ab_nueva$has_clicked)
X_vieja = mean(ab_vieja$has_clicked)
X_nueva
X_vieja
n_nueva = nrow(ab_nueva)
n_nueva
n_vieja = nrow(ab_vieja)
n_vieja
prop.test(sum(ab_nueva$has_clicked), n_nueva)
prop.test(sum(ab_vieja$has_clicked), n_vieja)
table(ab_nueva)
sum(ab_nueva$has_clicked)
# 1-sample proportions test with continuity correction
#
# data:  sum(ab_nueva$has_clicked) out of n_nueva, null probability 0.5
# X-squared = 257.13, df = 1, p-value < 2.2e-16
# alternative hypothesis: true p is not equal to 0.5
# 95 percent confidence interval:
#   0.2334439 0.2858338
# sample estimates:
#   p
# 0.2587917
prop.test(sum(ab_vieja$has_clicked), n_vieja)
# ------------------------------------------------------------------------------
counts = table(ab_testing)
counts
# table(ab_nueva)
prop.test(c(sum(ab_nueva$has_clicked), sum(ab_vieja)), c(n_nueva, n_vieja))
# table(ab_nueva)
prop.test(c(sum(ab_nueva$has_clicked), sum(ab_vieja$has_clicked)), c(n_nueva, n_vieja))
rowSums(counts)
prop.test(c(sum(ab_nueva$has_clicked), sum(ab_vieja$has_clicked)),
c(n_nueva, n_vieja),
alternative = "greater"
)
counts[1]
counts[1,]
